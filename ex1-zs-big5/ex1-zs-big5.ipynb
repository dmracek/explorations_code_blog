{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot Classify Scenario Responses in Terms of Big 5 Personality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this notebook I provide example Python code for how to classify text using zero-shot text classification. For in-depth details please see this [blog post](https://dmracek.github.io/explorations_code_nbs/exploration_zs_big5/).\n",
    "\n",
    "I provided comments throughout, however, the code should run as is.\n",
    "\n",
    "**If you're running this on a CPU and not a GPU I don't recommend re-running certain cells and instead recommend reading in the results from a previously outputted CSV**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "*These data are from the Society of Industrial Organizational Psychologists 2019 Machine Learning competition*:\n",
    "\n",
    "Scenario responses were designed to promote variability in terms of a specific Big 5 personality trait. Specifically,\n",
    "\n",
    "`open_ended_1` corresponds with string responses designed to elicit the **Agreeableness** personality trait.\n",
    "\n",
    "`open_ended_2` corresponds with string responses designed to elicit the **Conscientiousness** personality trait.\n",
    "\n",
    "`open_ended_3` corresponds with string responses designed to elicit the **Extraversion** personality trait.\n",
    "\n",
    "`open_ended_4` corresponds with string responses designed to elicit the **Neuroticism** personality trait.\n",
    "\n",
    "`open_ended_5` corresponds with string responses designed to elicit the **Openness** personality trait.\n",
    "\n",
    "* * *\n",
    "\n",
    "`a_scale_score` corresponds with a self-report questionnaire score for **Agreeableness**\n",
    "\n",
    "`c_scale_score` corresponds with a self-report questionnaire score for **Conscientiousness**\n",
    "\n",
    "`e_scale_score` corresponds with a self-report questionnaire score for **Extraversion**\n",
    "\n",
    "`n_scale_score` corresponds with a self-report questionnaire score for **Neuroticism**\n",
    "\n",
    "`o_scale_score` corresponds with a self-report questionnaire score for **Openness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers library.\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Import all dependencies and if available set device to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2070 with Max-Q Design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import torch\n",
    "\n",
    "from functools import reduce\n",
    "from pandas import json_normalize\n",
    "from transformers import pipeline\n",
    "from typing import Tuple\n",
    "\n",
    "# Set device on GPU if available else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "# Additional info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "classifier = pipeline('zero-shot-classification', device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Subset df to correspond with Big 5 personality trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('./data/siop_2019/siop_2019.csv')\n",
    "\n",
    "df_a = df_raw.loc[:, ['Respondent_ID', 'open_ended_1', 'Dataset']]\n",
    "df_c = df_raw.loc[:, ['Respondent_ID', 'open_ended_2', 'Dataset']]\n",
    "df_e = df_raw.loc[:, ['Respondent_ID', 'open_ended_3', 'Dataset']]\n",
    "df_n = df_raw.loc[:, ['Respondent_ID', 'open_ended_4', 'Dataset']]\n",
    "df_o = df_raw.loc[:, ['Respondent_ID', 'open_ended_5', 'Dataset']]\n",
    "\n",
    "# These will be our candidate labels\n",
    "big5_labels = ['agreeableness', 'conscientiousness', 'extraversion', 'neuroticism', 'openness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function\n",
    "\n",
    "Function to enumerate through responses for each of the prompts `open_ended_1` through `open_ended_5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zshot(df=df_a, \n",
    "          ids='Respondent_ID', \n",
    "          responses='open_ended_1', \n",
    "          split='Dataset', \n",
    "          labels=big5_labels, \n",
    "          hypothesis_template=('\"This response is characterized by {}.\"')) -> Tuple[pd.DataFrame]:\n",
    "    \n",
    "    '''\n",
    "    This function will classify text responses using Transformers zero-shot pipeline.\n",
    "    Arguments\n",
    "    ---------\n",
    "    df:                  Input pandas dataframe.\n",
    "    ids:                 Pandas column corresponding to primary key.\n",
    "    responses:           Pandas column corresponding to text to classify (e.g., scenario prompt).\n",
    "    split:               Pandas column corresponding to training split.\n",
    "    labels:              List for candidate_labels to classify\n",
    "    hypothesis_template: String the pipeline turns labels into hypotheses for NLI.\n",
    "    '''\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ids = df[ids]\n",
    "    sequences = df[responses].values\n",
    "    training_split = df[split]\n",
    "\n",
    "    # CREATE EMPTY LIST TO APPEND RESULTS \n",
    "    list_data = []\n",
    "\n",
    "    # ENUMERATE THROUGH RESPONSES USING ZERO SHOT CLASSIFIER PIPELINE \n",
    "    for idx, sequence in enumerate(sequences):\n",
    "        # MULTI_CLASS=True SCORES WILL BE INDEPENDENT YET FALL BETWEEN 0 AND 1\n",
    "        json_a = classifier(sequence, labels, multi_class=True, hypothesis_template=hypothesis_template)\n",
    "        list_data.append(json_a)\n",
    "\n",
    "    cl = json_normalize(list_data)\n",
    "\n",
    "    srs_ids, srs_split, srs_index  = ids, training_split, cl.sequence\n",
    "\n",
    "    # EXPLODE JSON LABELS INTO PANDAS COLUMNS\n",
    "    cl_labels = cl.explode('labels')\n",
    "    srs_labels = cl_labels['labels']\n",
    "    \n",
    "    # EXPLODE JSON SCORES INTO PANDAS COLUMNS\n",
    "    cl_scores = cl.explode('scores')\n",
    "    srs_scores = cl_scores['scores']\n",
    " \n",
    "    frame = { 'response_id': srs_ids, 'text': srs_index, 'split': srs_split, 'candidate_label_id': srs_labels, 'candidate_label_raw': srs_scores }\n",
    "\n",
    "    df_tall = pd.DataFrame(frame)\n",
    "\n",
    "    # CLEAN UP COLUMN STRING\n",
    "    df_tall['candidate_label_id'] = df_tall['candidate_label_id'].str.replace(\" \",\"_\")\n",
    "    df_tall['candidate_label_id'] = df_tall['candidate_label_id'].str.replace(\"-\",\"_\")\n",
    "    df_tall['split'] = df_tall['split'].str.lower()\n",
    "    # CONVERT TALL TO WIDE DATAFRAME\n",
    "    df_wide = df_tall.pivot(index='response_id', columns='candidate_label_id', values='candidate_label_raw').reset_index()\n",
    "\n",
    "    # MERGE in RESPONSE_ID, RESPONSES, SPLIT\n",
    "    df_split = df_tall.drop_duplicates(subset=['response_id']).loc[:, ['response_id', 'text', 'split']].reset_index(drop=True)\n",
    "    df_wide_ = pd.merge(df_wide, df_split, on='response_id', how='left')\n",
    "\n",
    "    df_wide_ = df_wide_.loc[:, ['response_id', 'agreeableness', 'conscientiousness', 'extraversion', 'neuroticism', 'openness']]\n",
    "\n",
    "    df_wide_ = df_wide_.rename(columns={\"agreeableness\": (\"agreeableness_\" + str(responses))})\n",
    "    df_wide_ = df_wide_.rename(columns={\"conscientiousness\": (\"conscientiousness_\" + str(responses))})\n",
    "    df_wide_ = df_wide_.rename(columns={\"extraversion\": (\"extraversion_\" + str(responses))})\n",
    "    df_wide_ = df_wide_.rename(columns={\"neuroticism\": (\"neuroticism_\" + str(responses))})\n",
    "    df_wide_ = df_wide_.rename(columns={\"openness\": (\"openness_\" + str(responses))})\n",
    "\n",
    "    return df_wide_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Warning** this will take a long time using CPU -- recommend testing a single line\n",
    "\n",
    "Transformer Pipeline Classification\n",
    "\n",
    "Note: I included candidate labels for all Big 5 traits even though each prompt is only designed to promote meaningful variability in terms of a single trait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agreeableness\n",
    "df_oe_a = zshot(df=df_a, ids='Respondent_ID', responses='open_ended_1', split='Dataset', labels=big5_labels)\n",
    "\n",
    "# Conscientiousness\n",
    "df_oe_c = zshot(df=df_c, ids='Respondent_ID', responses='open_ended_2', split='Dataset', labels=big5_labels)\n",
    "\n",
    "# Extraversion\n",
    "df_oe_e = zshot(df=df_e, ids='Respondent_ID', responses='open_ended_3', split='Dataset', labels=big5_labels)\n",
    "\n",
    "# Neuroticism\n",
    "df_oe_n = zshot(df=df_n, ids='Respondent_ID', responses='open_ended_4', split='Dataset', labels=big5_labels)\n",
    "\n",
    "# Openness\n",
    "df_oe_o = zshot(df=df_o, ids='Respondent_ID', responses='open_ended_5', split='Dataset', labels=big5_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and merge previous pipeline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>agreeableness_open_ended_1</th>\n",
       "      <th>conscientiousness_open_ended_1</th>\n",
       "      <th>extraversion_open_ended_1</th>\n",
       "      <th>neuroticism_open_ended_1</th>\n",
       "      <th>openness_open_ended_1</th>\n",
       "      <th>agreeableness_open_ended_2</th>\n",
       "      <th>conscientiousness_open_ended_2</th>\n",
       "      <th>extraversion_open_ended_2</th>\n",
       "      <th>neuroticism_open_ended_2</th>\n",
       "      <th>...</th>\n",
       "      <th>open_ended_2</th>\n",
       "      <th>open_ended_3</th>\n",
       "      <th>open_ended_4</th>\n",
       "      <th>open_ended_5</th>\n",
       "      <th>e_scale_score</th>\n",
       "      <th>a_scale_score</th>\n",
       "      <th>o_scale_score</th>\n",
       "      <th>c_scale_score</th>\n",
       "      <th>n_scale_score</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10430310916</td>\n",
       "      <td>0.961271</td>\n",
       "      <td>0.987350</td>\n",
       "      <td>0.517366</td>\n",
       "      <td>0.090582</td>\n",
       "      <td>0.851015</td>\n",
       "      <td>0.605696</td>\n",
       "      <td>0.993918</td>\n",
       "      <td>0.598209</td>\n",
       "      <td>0.278813</td>\n",
       "      <td>...</td>\n",
       "      <td>I would complete as much as possible as early ...</td>\n",
       "      <td>I would not go to the networking meeting. If I...</td>\n",
       "      <td>I would feel awful. I would discuss the negati...</td>\n",
       "      <td>The experience would be largely enjoyable. I m...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10430357581</td>\n",
       "      <td>0.949983</td>\n",
       "      <td>0.975450</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>0.128994</td>\n",
       "      <td>0.967695</td>\n",
       "      <td>0.236811</td>\n",
       "      <td>0.913796</td>\n",
       "      <td>0.217789</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>...</td>\n",
       "      <td>I would try to finish the project as early as ...</td>\n",
       "      <td>I would go regardless because this is an oppor...</td>\n",
       "      <td>You have to swallow your pride and move on. I ...</td>\n",
       "      <td>I would find this experience very enjoyable. L...</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10430389322</td>\n",
       "      <td>0.835928</td>\n",
       "      <td>0.991514</td>\n",
       "      <td>0.394194</td>\n",
       "      <td>0.397509</td>\n",
       "      <td>0.789948</td>\n",
       "      <td>0.805279</td>\n",
       "      <td>0.956355</td>\n",
       "      <td>0.517213</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>...</td>\n",
       "      <td>I would immediately make a priority list and p...</td>\n",
       "      <td>I would probably not go because I am not a big...</td>\n",
       "      <td>I would feel quite upset by the situation. I w...</td>\n",
       "      <td>I would find the experience enjoyable because ...</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10432456337</td>\n",
       "      <td>0.862493</td>\n",
       "      <td>0.976453</td>\n",
       "      <td>0.429553</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.797729</td>\n",
       "      <td>0.979905</td>\n",
       "      <td>0.659250</td>\n",
       "      <td>0.378568</td>\n",
       "      <td>...</td>\n",
       "      <td>I would try to get ad much done as soon as pos...</td>\n",
       "      <td>I would try to talk my colleague into going. I...</td>\n",
       "      <td>I would think long and hard about whether to r...</td>\n",
       "      <td>I would find it interesting. I love learning n...</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10432470791</td>\n",
       "      <td>0.871392</td>\n",
       "      <td>0.923793</td>\n",
       "      <td>0.565204</td>\n",
       "      <td>0.254818</td>\n",
       "      <td>0.737471</td>\n",
       "      <td>0.520573</td>\n",
       "      <td>0.971274</td>\n",
       "      <td>0.913008</td>\n",
       "      <td>0.376868</td>\n",
       "      <td>...</td>\n",
       "      <td>I would immediately start working. I like to g...</td>\n",
       "      <td>I would for sure try and get them to come alon...</td>\n",
       "      <td>I would reconnect with the boss and asked them...</td>\n",
       "      <td>I would find this experience enjoyable. Anytim...</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   response_id  agreeableness_open_ended_1  conscientiousness_open_ended_1  \\\n",
       "0  10430310916                    0.961271                        0.987350   \n",
       "1  10430357581                    0.949983                        0.975450   \n",
       "2  10430389322                    0.835928                        0.991514   \n",
       "3  10432456337                    0.862493                        0.976453   \n",
       "4  10432470791                    0.871392                        0.923793   \n",
       "\n",
       "   extraversion_open_ended_1  neuroticism_open_ended_1  openness_open_ended_1  \\\n",
       "0                   0.517366                  0.090582               0.851015   \n",
       "1                   0.812577                  0.128994               0.967695   \n",
       "2                   0.394194                  0.397509               0.789948   \n",
       "3                   0.429553                  0.809877               0.320497   \n",
       "4                   0.565204                  0.254818               0.737471   \n",
       "\n",
       "   agreeableness_open_ended_2  conscientiousness_open_ended_2  \\\n",
       "0                    0.605696                        0.993918   \n",
       "1                    0.236811                        0.913796   \n",
       "2                    0.805279                        0.956355   \n",
       "3                    0.797729                        0.979905   \n",
       "4                    0.520573                        0.971274   \n",
       "\n",
       "   extraversion_open_ended_2  neuroticism_open_ended_2  ...  \\\n",
       "0                   0.598209                  0.278813  ...   \n",
       "1                   0.217789                  0.030903  ...   \n",
       "2                   0.517213                  0.007445  ...   \n",
       "3                   0.659250                  0.378568  ...   \n",
       "4                   0.913008                  0.376868  ...   \n",
       "\n",
       "                                        open_ended_2  \\\n",
       "0  I would complete as much as possible as early ...   \n",
       "1  I would try to finish the project as early as ...   \n",
       "2  I would immediately make a priority list and p...   \n",
       "3  I would try to get ad much done as soon as pos...   \n",
       "4  I would immediately start working. I like to g...   \n",
       "\n",
       "                                        open_ended_3  \\\n",
       "0  I would not go to the networking meeting. If I...   \n",
       "1  I would go regardless because this is an oppor...   \n",
       "2  I would probably not go because I am not a big...   \n",
       "3  I would try to talk my colleague into going. I...   \n",
       "4  I would for sure try and get them to come alon...   \n",
       "\n",
       "                                        open_ended_4  \\\n",
       "0  I would feel awful. I would discuss the negati...   \n",
       "1  You have to swallow your pride and move on. I ...   \n",
       "2  I would feel quite upset by the situation. I w...   \n",
       "3  I would think long and hard about whether to r...   \n",
       "4  I would reconnect with the boss and asked them...   \n",
       "\n",
       "                                        open_ended_5  e_scale_score  \\\n",
       "0  The experience would be largely enjoyable. I m...       1.250000   \n",
       "1  I would find this experience very enjoyable. L...       3.250000   \n",
       "2  I would find the experience enjoyable because ...       2.916667   \n",
       "3  I would find it interesting. I love learning n...       2.416667   \n",
       "4  I would find this experience enjoyable. Anytim...       3.916667   \n",
       "\n",
       "   a_scale_score  o_scale_score  c_scale_score  n_scale_score  dataset  \n",
       "0       4.500000       3.500000       4.583333       2.000000    Train  \n",
       "1       4.583333       3.666667       4.750000       1.500000     Test  \n",
       "2       3.250000       4.083333       3.583333       2.833333     Test  \n",
       "3       4.166667       3.166667       3.833333       4.250000     Test  \n",
       "4       4.250000       4.833333       4.833333       1.500000    Train  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read\n",
    "df_a = pd.read_csv('./output/zshot_desc/df_a.csv')\n",
    "df_c = pd.read_csv('./output/zshot_desc/df_c.csv')\n",
    "df_e = pd.read_csv('./output/zshot_desc/df_e.csv')\n",
    "df_n = pd.read_csv('./output/zshot_desc/df_n.csv')\n",
    "df_o = pd.read_csv('./output/zshot_desc/df_o.csv')\n",
    "\n",
    "# Merge\n",
    "frames = [df_a, df_c, df_e, df_n, df_o]\n",
    "df_big5 = reduce(lambda left,right: pd.merge(left,right,on=['response_id', 'response_id'], how='outer'), frames)\n",
    "df_raw.columns = map(str.lower, df_raw.columns)\n",
    "df_merged = df_big5.merge(df_raw, left_on='response_id', right_on='respondent_id')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between zero-shot classification of a scenario response AND self-report questionnaire scores of corresponding Big 5 traits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self_report_big_5</th>\n",
       "      <th>zero_shot_predictions_of_sjt</th>\n",
       "      <th>r</th>\n",
       "      <th>p-unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_scale_score</td>\n",
       "      <td>agreeableness_open_ended_1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_scale_score</td>\n",
       "      <td>conscientiousness_open_ended_2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e_scale_score</td>\n",
       "      <td>extraversion_open_ended_3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_scale_score</td>\n",
       "      <td>neuroticism_open_ended_4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o_scale_score</td>\n",
       "      <td>openness_open_ended_5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  self_report_big_5    zero_shot_predictions_of_sjt     r  p-unc\n",
       "0     a_scale_score      agreeableness_open_ended_1  0.14   0.00\n",
       "1     c_scale_score  conscientiousness_open_ended_2  0.05   0.03\n",
       "2     e_scale_score       extraversion_open_ended_3  0.24   0.00\n",
       "3     n_scale_score        neuroticism_open_ended_4  0.01   0.55\n",
       "4     o_scale_score           openness_open_ended_5  0.22   0.00"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute correlations using Pingouin\n",
    "corr_a = pg.pairwise_corr(df_merged, columns=['a_scale_score', 'agreeableness_open_ended_1'], method='pearson')\n",
    "corr_c = pg.pairwise_corr(df_merged, columns=['c_scale_score', 'conscientiousness_open_ended_2'], method='pearson')\n",
    "corr_e = pg.pairwise_corr(df_merged, columns=['e_scale_score', 'extraversion_open_ended_3'], method='pearson')\n",
    "corr_n = pg.pairwise_corr(df_merged, columns=['n_scale_score', 'neuroticism_open_ended_4'], method='pearson')\n",
    "corr_o = pg.pairwise_corr(df_merged, columns=['o_scale_score', 'openness_open_ended_5'], method='pearson')\n",
    "\n",
    "# Combine results -- r is correlation -- p-unc is p-value\n",
    "corrs = [corr_a, corr_c, corr_e, corr_n, corr_o]\n",
    "df_corrs = pd.concat(corrs).loc[:, ['X', 'Y', 'r', 'p-unc']].round(2).reset_index(drop = True)\n",
    "df_corrs = df_corrs.rename({'X': 'self_report_big_5', 'Y': 'zero_shot_predictions_of_sjt'}, axis=1)\n",
    "df_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [blog post](https://dmracek.github.io/explorations_code_nbs/exploration_zs_big5/) for full write up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
